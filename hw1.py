# -*- coding: utf-8 -*-
"""HW1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Z_ChSiks_Ztf56iV6hilHwy-wcY5oxij

#主題:使用CNN分類衛星影像中的災害從而加速災害應對

## 1.1 安裝套件(若在colab訓練每次都需要執行)
"""

!pip install fastbook -q
# 安裝 gcsfs 與 datasets 支援的版本
!pip install gcsfs==2025.3.0 --no-deps
!pip install datasets==3.4.0 --no-deps

"""## 1.2 讀取套件"""

import fastbook
from fastbook import *
from fastai.vision.widgets import *
import torch
import shutil
from google.colab import drive
from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc
from torchvision.transforms.functional import to_tensor
from fastai.vision.all import PILImage, Resize, ResizeMethod, PadMode
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np

"""### 設定裝置"""

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
device

import shutil
import fastai;
print('fastai verison:', fastai.__version__)
print('torch version:', torch.__version__)

"""## 1.3 準備資料集

### 掛載到google drive
"""

from google.colab import drive
drive.mount('/content/drive')

"""### 設定專案名稱"""

project = 'demo'
path = Path('/content/drive/MyDrive/DeepLearning/0225/dataset/'+project)

"""#Key is the name of classes; value is the keyword that which search engine uses for searching
keywords = {
    'Aerial photo of the fire': 'Aerial photo of the fire',
    'Drought aerial photo': 'Drought aerial photo',
    'Aerial photo of flood': 'Aerial photo of flood',
    'Aerial photo of volcano': 'Aerial photo of volcano',
    'Typhoon satellite photos': 'Typhoon satellite photos'
}
array = keywords.items()
#Satellite photos of the fire火災衛星照片
#Drought satellite photos乾旱衛星照片
#Satellite photos of floods水災衛星照片
#Satellite photos of volcanic eruptions火山爆發衛星照片
#Satellite photos of heavy rain豪雨衛星照片
#Typhoon satellite photos颱風衛星照片

project_folder = f'/content/drive/MyDrive/DeepLearning/0225/dataset/{project}'

if not path.exists():
    !mkdir -p {project_folder}
else:
    print('The Project Folder exists; it will be removed and created again.')
    shutil.rmtree(project_folder)
    !mkdir -p {project_folder}

#網路爬蟲下載圖片
for key,value in array:
    print(key,value)
    dest = (path/key)
    dest.mkdir(exist_ok=True)
    urls = search_images_ddg(f' {value}',max_images=300)  # DuckDuckGo圖像搜尋引擎
    download_images(dest, urls=urls)

## 1.4 清洗資料
"""

fns = get_image_files(path) # 找出所有圖像檔案
failed = verify_images(fns) #將所有無效的圖像檔案路徑儲存於變數failed中
failed.map(Path.unlink) # 刪除無效的圖像檔案

"""## 2.1 設定訓練資料路徑"""

path = Path('/content/drive/MyDrive/DeepLearning/0225/dataset/demo')
path.ls()

from google.colab import drive
drive.mount('/content/drive')

"""### 建立模型權重儲存路徑"""

myPath='/content/drive/MyDrive/DeepLearning/0225/models'
!mkdir -p $myPath

"""## 2.2 資料讀取框架

### 數據集切割比例(8:1:1)
"""

dataset = DataBlock(
    blocks=(ImageBlock, CategoryBlock), #定義輸入和輸出的資料類型(輸入:圖片/輸出:分類標籤)
    get_items=get_image_files,  #告訴 fastai 如何獲取資料
    splitter=RandomSplitter(valid_pct=0.1, seed=42),#10%的資料用於驗證集，剩下的90%用於訓練集
    item_tfms=Resize(224),#將所有圖片調整為 224x224 像素
    get_y=parent_label,#從圖片的父資料夾名稱獲取標籤
)

# 利用框架正式讀取資料
# 批次大小（batch size），每次訓練或驗證時處理 16 張圖片
# 使用 16 個workers來並行載入資料，加快資料準備速度
# dataset.dataloaders 是從你的數據集（dataset）生成一個數據加載器
dls = dataset.dataloaders(path,bs=16,num_workers=16)

# 計算分配後的資料集大小
train_size = len(dls.train_ds)
valid_size = len(dls.valid_ds)

# 計算測試集大小 (從訓練集和驗證集中總共分配 10% 作為測試集)
total_size = train_size + valid_size
test_size = int(0.1 * total_size)  # 10% 作為測試集

# 現在，更新訓練集的大小 (剩餘的 80%)
train_size = total_size - valid_size - test_size

print(f'Train: {train_size}, Validation: {valid_size}, Test: {test_size}')

"""## 2.3 讀取圖檔結果(確保圖像已正確載入)

用於視覺化檢查資料載入器產生的圖像資料，有助於確保資料品質和正確性
"""

print('訓練資料')
dls.show_batch(max_n=9, nrows=1) #從訓練集中抽出9個樣本   nrows=顯示的行數
#這邊顯示出來的圖片和標籤是我提供給fastai的資料，不是模型自己預測的結果

"""## 3.1選擇模型架構以及對應的預測訓練權重

NOTE: metrics是模型訓練人員觀察的指標，可設定多個

### 定義模型列表

*   ResNet 透過殘差連接解決深層網路訓練問題。
*   VGG 透過簡單的堆疊方式加深網路。
*   EfficientNet 透過複合縮放技術，在準確度和效率之間取得平衡。
"""

models = {
    "ResNet34": resnet34,
    "Vgg16": vgg16,
    "EfficientNet": efficientnet_b0
}

results = {}

"""## 訓練並儲存模型權重檔

微調（fine-tuning）的原理：

*   微調是在預訓練模型（例如在 ImageNet 上訓練的模型）的基礎上，針對新的資料集進行再訓練。
*   目的是讓模型能夠適應新的資料集，並提高在特定任務上的效能。

overfitting觀察

*   `train_loss` 持續下降，但 `valid_loss` 開始上升或停滯不前
"""

for model_name, model_arch in models.items():
    print(f"Training {model_name}...")
    learn = vision_learner(dls, model_arch, metrics=[accuracy], pretrained=True) #pretrained=True表示使用了在 ImageNet 這樣的大型資料集上訓練過的模型
    #fine-tuning，在已經預訓練的權重上進行再訓練，共3次
    learn.fine_tune(3)

    model_path = f'/content/drive/MyDrive/DeepLearning/0225/models/{model_name}.pkl'
    learn.export(model_path)

"""## 顯示預測結果"""

y_pred, y_true = learn.get_preds()  # 這會返回預測結果和真實標籤
print(f"y_pred shape: {y_pred.shape}, y_true shape: {y_true.shape}")
print(f"y_pred unique values: {y_pred.unique()}")
print(f"y_true unique values: {y_true.unique()}")

"""### `y_pred shape: torch.Size([93, 5])`
意味著有 93 個樣本，每個樣本有 5 個預測的機率值

### `y_true shape: torch.Size([93])`
意味著你有 93 個樣本的真實標籤。每個標籤是對應的類別編號（例如，0 到 4，這意味著有 5 類標籤）

## 預測模型的準確度

### 針對之前訓練並儲存的每個模型，載入模型、評估模型在驗證資料集上的準確度，並將結果儲存起來
"""

for model_name, model_arch in models.items():
    # Load the learner for the specific model
    model_path = f'/content/drive/MyDrive/DeepLearning/0225/models/{model_name}.pkl'
    learn = load_learner(model_path) # Load the specific learner

    preds, y_true, _ = learn.get_preds(with_loss=True, dl=dls.valid) # Specify the dataloader for get_preds
    y_pred = preds.argmax(dim=1)

    # **確保 y_true 是類別索引，而不是 one-hot 編碼**
    if y_true.ndim > 1 and y_true.shape[1] > 1:
        y_true = y_true.argmax(dim=1)  # Convert one-hot to class index

    acc = accuracy(preds, y_true).item()

    # Print or store the accuracy for each model
    print(f"Accuracy for {model_name}: {acc}")
    results[model_name] = acc

"""## 3.3解凍權重再次訓練

### 尋找最佳學習率
在訓練 AI 模型時，學習率太小，訓練會變慢；學習率太大，模型可能學不好甚至發散。這些圖幫助你找到一個 「剛剛好」 的學習率，讓訓練既快又穩定。



*   學習率太大時 (右側區域)，損失值急劇上升，代表模型開始學壞了
*   選擇橘色點 (minimum) 附近，可能會讓模型學得更準確
*   選擇綠色點 (steep) 附近，初始學習速度會快
"""

results = {}
for model_name, model_arch in models.items():
    # 讀取模型
    model_path = f'/content/drive/MyDrive/DeepLearning/0225/models/{model_name}.pkl'
    learn = load_learner(model_path)

    # 確保 DataLoaders 設置正確
    learn.dls = dls
    learn.unfreeze()

    # 找最佳學習率
    lr_min, lr_steep = learn.lr_find(suggest_funcs=(minimum, steep), end_lr=5, num_it=200)

    # 訓練 6 個 epochs
    print(f"Training {model_name} with lr_max={lr_min:.2e}...")
    learn.fit_one_cycle(6, lr_max=lr_min)

    # 記錄結果
    results[model_name] = {'lr_min': lr_min, 'lr_steep': lr_steep}
    print(f"Finished training {model_name}\n")

print("All models trained:", results)

"""## 3.4儲存新的權重"""

export_path = "/content/drive/MyDrive/DeepLearning/0225/models/exported"  # 設定存放路徑
os.makedirs(export_path, exist_ok=True)  # 確保目錄存在

for model_name, model_arch in models.items():
    # 讀取模型
    model_path = f'/content/drive/MyDrive/DeepLearning/0225/models/{model_name}.pkl'
    learn = load_learner(model_path)

    # 確保模型正確載入
    if learn is None:
        print(f"Skipping {model_name}: Failed to load model.")
        continue

    # 設定輸出路徑
    export_file = f"{export_path}/{model_name}_export.pkl"

    # 導出模型
    learn.export(export_file)
    print(f"Exported {model_name} to {export_file}")

print("All models exported successfully!")

"""## 4.1結果檢核(Confusion Matrix)"""

# Iterate through each model
for model_name, model_arch in models.items():
    # Load the learner for the specific model
    model_path = f'/content/drive/MyDrive/DeepLearning/0225/models/exported/{model_name}_export.pkl'
    learn = load_learner(model_path)  # Load the specific learner

    # Get predictions and true labels
    preds, y_true, _ = learn.get_preds(with_loss=True, dl=dls.valid)  # Specify the dataloader for get_preds
    y_pred = preds.argmax(dim=1)

    # Create interpretation object
    interp = ClassificationInterpretation.from_learner(learn, dl=dls.valid)

    # Plot confusion matrix
    print(f"Confusion Matrix for {model_name}:")
    interp.plot_confusion_matrix()

"""### 找出每個模型預測錯誤最嚴重的樣本"""

# 迭代每個模型
for model_name, model_arch in models.items():
    # 使用新的權重檔案來加載模型
    new_model_path = f'/content/drive/MyDrive/DeepLearning/0225/models/exported/{model_name}_export.pkl'
    learn = load_learner(new_model_path)  # 加載新的學習器

    # 獲取預測結果和真實標籤
    preds, y_true, _ = learn.get_preds(with_loss=True, dl=dls.valid)  # 指定dataloader進行預測
    y_pred = preds.argmax(dim=1)

    # 創建解釋對象
    interp = ClassificationInterpretation.from_learner(learn, dl=dls.valid)

    # 顯示前 5 個錯誤最嚴重的分類結果
    print(f"Top 5 losses for {model_name}:")
    interp.plot_top_losses(5, nrows=5)

"""## 預測"""

## 模型位置
from fastbook import *
from fastai.vision.widgets import *
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
device

"""## 5.1讀取先前訓練好的權重"""

myPath = '/content/drive/MyDrive/DeepLearning/0225/models/exported/'

# List your model files
model_files = [
    'ResNet34_export.pkl',
    'Vgg16_export.pkl',
    'EfficientNet_export.pkl'
]

# Load all the models
learners = []
for model_file in model_files:
    model_path = f'{myPath}/{model_file}'
    learn = load_learner(model_path)  # Load the model
    learners.append(learn)  # Store each learner in the list

# Now you have a list `learners` that contains the loaded models

"""## 5.2讀取檔案並送入模型預測"""

##執行預測 -method I
# get_image_files is now available
fnames_fire = get_image_files('/content/drive/MyDrive/DeepLearning/0225/dataset/demo/Aerial photo of the fire')
fnames_Drought = get_image_files('/content/drive/MyDrive/DeepLearning/0225/dataset/demo/Drought aerial photo')
fnames_floods = get_image_files('/content/drive/MyDrive/DeepLearning/0225/dataset/demo/Aerial photo of flood')
fnames_volcanic = get_image_files('/content/drive/MyDrive/DeepLearning/0225/dataset/demo/Aerial photo of volcano')
fnames_Typhoon = get_image_files('/content/drive/MyDrive/DeepLearning/0225/dataset/demo/Typhoon satellite photos')


print(f"Number of fire images: {len(fnames_fire)}")
print(f"Number of drought images: {len(fnames_Drought)}")
print(f"Number of floods images: {len(fnames_floods)}")
print(f"Number of volcano images: {len(fnames_volcanic)}")
print(f"Number of typhoon images: {len(fnames_Typhoon)}")

"""### 對多個類別的圖片進行預測"""

#  learners 是已經加載的多個模型列表
categories = {
    "Fire": fnames_fire,
    "Drought": fnames_Drought,
    "Floods": fnames_floods,
    "Volcanic": fnames_volcanic,
    "Typhoon": fnames_Typhoon
}

# 儲存每個類別的預測結果
category_predictions = {}

# 針對每個類別的影像進行預測
for category, fnames in categories.items():
    category_predictions[category] = []  # 初始化該類別的預測列表

    for learn in learners:
        # 檢查列表中是否有足夠的影像數量
        if len(fnames) > 3:
            # 預測該類別中的第 4 張圖片（索引為 3）
            pred_class, pred_idx, outputs = learn.predict(fnames[3])
            category_predictions[category].append((learn, pred_class))  # 儲存每個模型的預測結果
            print(f"Model Prediction for {category}: {pred_class}")
        else:
            print(f"{category} does not have enough elements to access index 3")

# 顯示所有類別的預測結果
print("All model predictions for each category:")
for category, predictions in category_predictions.items():
    print(f"\nPredictions for {category}:")
    for model, pred in predictions:
        print(f"Model: {model} - Predicted Class: {pred}")

"""## ROC curve

*   橫軸是假陽性率（FPR），縱軸是真陽性率（TPR）
*   ROC 曲線（Receiver Operating Characteristic Curve，接收者操作特徵曲線）是一種用於評估分類模型性能的圖形工具，特別是在二元分類問題中（例如判斷「是/否」、「正/負」）
*   AUC（Area Under the Curve） 是 ROC 曲線下的面積，範圍從 0 到 1
*   AUC 的解釋
  *   AUC=1：完美模型，100%正確分類。
  *   AUC=0.5：隨機猜測，模型毫無區分能力（ROC 曲線是一條對角線）。
  *   AUC<0.5：模型比隨機猜測還差（可能是標籤錯誤或模型反向預測）。
"""

# 假設 learners 是一個包含三個已加載模型的列表
models = ["ResNet34", "Vgg16", "EfficientNet"]  # 這是你的模型名稱
learners = []  # 這是包含你三個已加載模型的 learners 列表
myPath = '/content/drive/MyDrive/DeepLearning/0225/models/exported/'

# List your model files
model_files = [
    'ResNet34_export.pkl',
    'Vgg16_export.pkl',
    'EfficientNet_export.pkl'
]

# Load all the models and add them to the 'learners' list
for model_file in model_files:
    model_path = f'{myPath}/{model_file}'
    learn = load_learner(model_path)  # Load the model
    learners.append(learn)  # Store each learner in the list


# 讀取資料集（用於獲取 y）
preds_all_models = []
y_all_models = []

# 取得所有模型的預測結果
for learn in learners:
    preds, y, _ = learn.get_preds(with_loss=True, dl=dls.valid)  # 獲取預測結果和真實標籤
    preds_all_models.append(preds)
    y_all_models.append(y)

# 設定類別數和類別名稱
class_num = dls.c
class_name = dls.vocab

# 迴圈繪製每個模型的ROC曲線並保存為獨立的圖片
for model_idx, (preds, y) in enumerate(zip(preds_all_models, y_all_models)):
    # 為每個模型創建新圖
    plt.figure(figsize=(8, 8))

    # 迭代每個類別
    for i in range(class_num):
        probs = np.array(preds[:, i])

        # 計算ROC曲線
        fpr, tpr, thresholds = roc_curve(y, probs, pos_label=i)

        # 計算AUC
        roc_auc = auc(fpr, tpr)

        # 繪製ROC曲線
        plt.plot(fpr, tpr, label=f'{models[model_idx]} - {class_name[i]} (AUC={round(roc_auc, 3)})')

    # 繪製對角線（隨機猜測的線）
    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')

    # 設定繪圖範圍和標籤
    plt.xlim([-0.01, 1.01])
    plt.ylim([-0.01, 1.01])
    plt.axis('square')
    plt.xlabel("False Positive Rate")
    plt.ylabel("True Positive Rate")
    plt.title(f"ROC curve for {models[model_idx]}")
    plt.legend(loc="lower right")

    ## 顯示roc curve
    plt.show()

    # 儲存每個模型的ROC圖
    plt.savefig(f'/content/drive/MyDrive/DeepLearning/0225/models/exported/{models[model_idx]}_roc_curve.png')
    plt.close()  # 關閉該圖表，避免重疊

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
import numpy as np

# 模型名稱
models = ["ResNet34", "Vgg16", "EfficientNet"]

# 儲存每個模型的結果
model_results = {}

# 取得所有模型的預測結果
for model_idx, (preds, y) in enumerate(zip(preds_all_models, y_all_models)):
    # 取得每個模型的預測結果和真實標籤
    y_true = y
    y_pred = np.argmax(preds, axis=1)  # 假設預測結果是概率，選擇最高的預測類別

    # 計算每個模型的各種指標
    accuracy = accuracy_score(y_true, y_pred)
    precision = precision_score(y_true, y_pred, average='weighted')  # 加權平均
    recall = recall_score(y_true, y_pred, average='weighted')  # 加權平均
    f1 = f1_score(y_true, y_pred, average='weighted')  # 加權平均
    auc = roc_auc_score(y_true, preds, multi_class='ovr', average='weighted')  # AUC (使用 'one-vs-rest' 策略)

    # 儲存結果
    model_results[models[model_idx]] = {
        'Accuracy': accuracy,
        'Precision': precision,
        'Recall': recall,
        'F1-Score': f1,
        'AUC': auc
    }

    # 顯示每個模型的指標
    print(f"Metrics for {models[model_idx]}:")
    print(f"Accuracy: {accuracy:.4f}")
    print(f"Precision: {precision:.4f}")
    print(f"Recall: {recall:.4f}")
    print(f"F1-Score: {f1:.4f}")
    print(f"AUC: {auc:.4f}")
    print("-" * 40)

# 顯示所有模型的結果
print("Summary of Model Performance:")
for model_name, results in model_results.items():
    print(f"\n{model_name}:")
    for metric, value in results.items():
        print(f"{metric}: {value:.4f}")

"""##6.Visualization with Grad-CAM

Class Activation Mapping（類激活映射，簡稱CAM）是一種用於解釋卷積神經網路（CNN）預測的可視化技術。它可以幫助我們理解CNN在圖像分類任務中，哪些區域對最終預測貢獻最大。簡單來說，CAM生成一個熱圖（heatmap），顯示圖像中哪些部分對某個特定類別的預測最重要。
"""

class Hook():
  def __init__(self,m):
    self.hook = m.register_forward_hook(self.hook_fn)
  def hook_fn(self,m,i,o):self.stored = o.detach().clone()
  def __enter__(self, *args):return self
  def __exit__(self, *args):self.hook.remove()

class HookBwd():
  def __init__(self,m):
    self.hook = m.register_backward_hook(self.hook_fn)
  def hook_fn(self,m,gi,go):self.stored = go[0].detach().clone()
  def __enter__(self, *args):return self
  def __exit__(self, *args):self.hook.remove()

"""##讀取要繪製的影像"""

fnames_fire = get_image_files('/content/drive/MyDrive/DeepLearning/0225/dataset/demo/Aerial photo of the fire')
test_dl = learn.dls.test_dl(fnames_fire, with_labels=True)

fnames_Drought = get_image_files('/content/drive/MyDrive/DeepLearning/0225/dataset/demo/Drought aerial photo')
test_dl = learn.dls.test_dl(fnames_Drought, with_labels=True)

fnames_floods = get_image_files('/content/drive/MyDrive/DeepLearning/0225/dataset/demo/Aerial photo of flood')
test_dl = learn.dls.test_dl(fnames_floods, with_labels=True)

fnames_volcanic = get_image_files('/content/drive/MyDrive/DeepLearning/0225/dataset/demo/Aerial photo of volcano')
test_dl = learn.dls.test_dl(fnames_volcanic, with_labels=True)

fnames_Typhoon = get_image_files('/content/drive/MyDrive/DeepLearning/0225/dataset/demo/Typhoon satellite photos')
test_dl = learn.dls.test_dl(fnames_Typhoon, with_labels=True)

from torchvision.transforms.functional import to_tensor
from fastai.vision.all import PILImage, Resize, ResizeMethod, PadMode  # 導入 fastai 模組
fn = test_dl.items[1] #第2張影像
x_dec = PILImage.create(fn);

#Resize : 224填充黑邊
rsz = Resize(224, method=ResizeMethod.Pad, pad_mode=PadMode.Zeros)
x_dec = rsz(x_dec)
x = to_tensor(x_dec)
x.unsqueeze_(0)
x.shape,type(x)

"""##繪製最後一層的feature map 的Grad-CAM"""

cls = 1
with HookBwd(learn.model[0]) as hookg:
  with Hook(learn.model[0]) as hook:
    #output = learn.model.eval()(x,cuda())
    output = learn.model.eval()(x.cpu())
    act = hook.stored
  output[0,cls].backward()
  grad = hookg.stored

w = grad[0].mean(dim=[1,2], keepdim=True)
cam_map = (w * act[0]).sum(0)

"""##Demo"""

_,ax = plt.subplots()
x_dec.show(ctx=ax)
ax.imshow(cam_map.detach().cpu(), alpha=0.6, extent=(0,224,224,0),
           interpolation='bilinear', cmap='magma')