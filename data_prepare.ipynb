{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BBrain778/CNN/blob/main/data_prepare.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QkpostKfzhOi"
      },
      "source": [
        "#主題:使用CNN分類衛星影像中的災害從而加速災害應對\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8WLbB0NCY_h"
      },
      "source": [
        "## 1.1 安裝套件(若在colab訓練每次都需要執行)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "wcsh3TQvCi1g",
        "outputId": "7517e4a3-b883-46f6-d50d-fb9f6c62cf40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m719.8/719.8 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m60.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m48.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2024.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install fastbook -q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BgqWjxNwCkjZ"
      },
      "source": [
        "## 1.2 讀取套件"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cE55Ru39QO3",
        "outputId": "40b60add-5d52-480b-b4d3-e1e28a9dd373"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from fastbook import *\n",
        "from fastai.vision.widgets import *\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17Al74d8UkMU",
        "outputId": "6e317dbf-45f1-4f4f-b438-64896d04d813"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fastai verison: 2.7.19\n",
            "torch version: 2.6.0+cu124\n"
          ]
        }
      ],
      "source": [
        "import shutil\n",
        "import fastai;\n",
        "print('fastai verison:', fastai.__version__)\n",
        "print('torch version:', torch.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16lyRNm99e9M"
      },
      "source": [
        "\n",
        "## 1.3 準備資料集"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NGac0iS1_htj",
        "outputId": "21e2f302-8bbb-4ae1-8d3f-96ebdc309c62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#將 Google Drive 掛載到 /content/drive，以便存取或保存檔案\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c6aoC4YBAr6T"
      },
      "outputs": [],
      "source": [
        "#set project name\n",
        "project = 'demo'\n",
        "\n",
        "path = Path('/content/drive/MyDrive/DeepLearning/0225/dataset/'+project)\n",
        "\n",
        "#Key is the name of classes; value is the keyword that which search engine uses for searching\n",
        "keywords = {'Satellite photos of the fire': 'Satellite photos of the fire', 'Drought satellite photos': 'Drought satellite photos', 'Satellite photos of floods': 'Satellite photos of floods', 'Satellite photos of volcanic eruptions': 'Satellite photos of volcanic eruptions', 'Satellite photos of heavy rain': 'Satellite photos of heavy rain', 'Typhoon satellite photos': 'Typhoon satellite photos'}\n",
        "array = keywords.items()\n",
        "#Satellite photos of the fire火災衛星照片\n",
        "#Drought satellite photos乾旱衛星照片\n",
        "#Satellite photos of floods水災衛星照片\n",
        "#Satellite photos of volcanic eruptions火山爆發衛星照片\n",
        "#Satellite photos of heavy rain豪雨衛星照片\n",
        "#Typhoon satellite photos颱風衛星照片\n",
        "\n",
        "project_folder = f'/content/drive/MyDrive/DeepLearning/0225/dataset/{project}'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IARVPHmT9iLy",
        "outputId": "4b0625ac-66db-45d1-a1d7-4b235c59b8fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The Project Folder exists; it will be removed and created again.\n",
            "Satellite photos of the fire Satellite photos of the fire\n",
            "Drought satellite photos Drought satellite photos\n",
            "Satellite photos of floods Satellite photos of floods\n",
            "Satellite photos of volcanic eruptions Satellite photos of volcanic eruptions\n",
            "Satellite photos of heavy rain Satellite photos of heavy rain\n",
            "Typhoon satellite photos Typhoon satellite photos\n"
          ]
        }
      ],
      "source": [
        "if not path.exists():\n",
        "    !mkdir -p {project_folder}\n",
        "else:\n",
        "    print('The Project Folder exists; it will be removed and created again.')\n",
        "    shutil.rmtree(project_folder)\n",
        "    !mkdir -p {project_folder}\n",
        "\n",
        "#網路爬蟲下載圖片\n",
        "for key,value in array:\n",
        "    print(key,value)\n",
        "    dest = (path/key)\n",
        "    dest.mkdir(exist_ok=True)\n",
        "    urls = search_images_ddg(f' {value}',max_images=100)\n",
        "    download_images(dest, urls=urls)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHhF6RV-9pS8"
      },
      "source": [
        "## 1.4 清洗資料"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6IZVcyZM9ra1",
        "outputId": "10a2e573-f9c1-43dd-9064-937bfe1d9360"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(#31) [None,None,None,None,None,None,None,None,None,None,None,None,None,None,None,None,None,None,None,None...]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fns = get_image_files(path)\n",
        "failed = verify_images(fns)\n",
        "failed.map(Path.unlink) #unlink broken images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocnI5vWFJEWc"
      },
      "source": [
        "## 2.1 設定訓練資料路徑"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VHAh-JrlJMM3",
        "outputId": "106b2edf-e2d7-4f4c-9625-d1c062814cf3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(#6) [Path('/content/drive/MyDrive/DeepLearning/0225/dataset/demo/Satellite photos of the fire'),Path('/content/drive/MyDrive/DeepLearning/0225/dataset/demo/Drought satellite photos'),Path('/content/drive/MyDrive/DeepLearning/0225/dataset/demo/Satellite photos of floods'),Path('/content/drive/MyDrive/DeepLearning/0225/dataset/demo/Satellite photos of volcanic eruptions'),Path('/content/drive/MyDrive/DeepLearning/0225/dataset/demo/Satellite photos of heavy rain'),Path('/content/drive/MyDrive/DeepLearning/0225/dataset/demo/Typhoon satellite photos')]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "path = Path('/content/drive/MyDrive/DeepLearning/0225/dataset/demo')\n",
        "path.ls()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1X0KHRMHK56",
        "outputId": "ad3402c9-0813-4eda-d081-84e0fbaaa68d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0u7gqSOYJj59"
      },
      "outputs": [],
      "source": [
        "#建立模型權重儲存路徑\n",
        "myPath='/content/drive/MyDrive/DeepLearning/0225/models'\n",
        "!mkdir -p $myPath"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8VZVeUpFKMRQ"
      },
      "source": [
        "## 2.2 資料讀取框架"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "ixwJdZCQKPQ8",
        "outputId": "76c6cb71-10e0-47f6-a687-2e308e067553"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "property 'valid_ds' of 'DataLoaders' object has no setter",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-02fd61e98780>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# 更新驗證集 (只保留 10%)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mdls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalid_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalid_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_empty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0mdls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalid_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mall_valid_items\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalid_idx\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Update items in the new dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: property 'valid_ds' of 'DataLoaders' object has no setter"
          ]
        }
      ],
      "source": [
        "dataset = DataBlock(\n",
        "    blocks=(ImageBlock, CategoryBlock), #定義輸入和輸出的資料類型(輸入:圖片/輸出:分類標籤)\n",
        "    get_items=get_image_files,  #告訴 fastai 如何獲取資料\n",
        "    splitter=RandomSplitter(valid_pct=0.2, seed=42),#20%的資料用於驗證集，剩下的80%用於訓練集\n",
        "    item_tfms=Resize(224),#將所有圖片調整為 224x224 像素\n",
        "    get_y=parent_label,#從圖片的父資料夾名稱獲取標籤\n",
        ")\n",
        "\n",
        "#利用框架正式讀取資料\n",
        "# 批次大小（batch size），每次訓練或驗證時處理 16 張圖片\n",
        "# 使用 16 個工作線程來並行載入資料，加快資料準備速度（特別在 GPU 環境中很有用）\n",
        "dls = dataset.dataloaders(path,bs=16,num_workers=16) #dataset.dataloaders 是從你的數據集（dataset）生成一個數據加載器\n",
        "\n",
        "\n",
        "\n",
        "#讀取結果\n",
        "#print(dls.c, dls.vocab, len(dls.train_ds), len(dls.valid_ds)) #dls.c=類別數量(5) dls.vocab=標籤詞彙表 len(dls.train_ds)=訓練樣本數量(80%) len(dls.valid_ds)=驗證數量(20%)\n",
        "#print(dls.c, dls.vocab, len(dls.train_ds), len(dls.valid_ds), len(dls.test_ds))\n",
        "\n",
        "# 從驗證集分出測試集 (將 20% 分成 10% 驗證 + 10% 測試)\n",
        "all_valid_items = dls.valid_ds.items  # 獲取驗證集的所有檔案\n",
        "valid_test_splitter = RandomSplitter(valid_pct=0.5, seed=42)  # 從驗證集中再分一半\n",
        "valid_idx, test_idx = valid_test_splitter(all_valid_items)\n",
        "\n",
        "# 更新驗證集 (只保留 10%)\n",
        "dls.valid_ds = dls.valid_ds.new_empty()\n",
        "dls.valid_ds.items = [all_valid_items[i] for i in valid_idx]  # Update items in the new dataset\n",
        "\n",
        "dls.valid = dls.valid.new(get_items=dls.valid_ds.items)\n",
        "# 建立測試集 DataLoader\n",
        "test_items = [all_valid_items[i] for i in test_idx]\n",
        "test_dls = dls.valid.new(get_items=test_items)\n",
        "\n",
        "# 讀取結果\n",
        "print(f\"類別數量: {dls.c}\")\n",
        "print(f\"標籤詞彙表: {dls.vocab}\")\n",
        "print(f\"訓練集樣本數: {len(dls.train_ds)} ({len(dls.train_ds)/len(get_image_files(path))*100:.1f}%)\")\n",
        "print(f\"驗證集樣本數: {len(dls.valid_ds)} ({len(dls.valid_ds)/len(get_image_files(path))*100:.1f}%)\")\n",
        "print(f\"測試集樣本數: {len(test_dls.dataset)} ({len(test_dls.dataset)/len(get_image_files(path))*100:.1f}%)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pMeRakmhKSbH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3YMQq3JLO91"
      },
      "source": [
        "## 2.3 讀取圖檔結果"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lf06_-EiLR3H"
      },
      "outputs": [],
      "source": [
        "print('訓練資料')\n",
        "dls.show_batch(max_n=9, nrows=1) #從訓練集中抽出9個樣本   nrows=顯示的行數\n",
        "#這邊顯示出來的圖片和標籤是我提供給fastai的資料，不是模型自己預測的結果\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5O9fJfPQMy0H"
      },
      "source": [
        "## 3.1選擇模型架構以及對應的預測訓練權重\n",
        "\n",
        "NOTE: metrics是模型訓練人員觀察的指標，可設定多個"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xpWEnENRM5ro"
      },
      "outputs": [],
      "source": [
        "# vision_learner是 fastai 庫中專門用於圖像視覺任務的函數，用來構建一個圖像分類模型\n",
        "# dls 包含了訓練數據和驗證數據（通常是圖像數據及其標籤），並且已經被預處理，用來告訴模型“這些是我的數據，準備好用它們來訓練吧”\n",
        "# resnet34 是模型的架構（architecture），具體來說是 ResNet-34，一種經典的卷積神經網絡（CNN），特別適合圖像分類任務\n",
        "# metrics=[accuracy, error_rate]這些是在訓練過程中用來評估模型性能的指標\n",
        "# pretrained=True表示使用預訓練的權重來初始化模型，ResNet-34 已經在 ImageNet（一個包含數百萬張圖像的大型數據集）上訓練過，因此它已經學會了識別圖像中的基本特徵（比如邊緣、形狀等）\n",
        "\n",
        "\n",
        "\n",
        "learn = vision_learner(dls, resnet34, metrics=[accuracy, error_rate], pretrained=True)\n",
        "learn.fit_one_cycle(3, 1e-3)\n",
        "\n",
        "#總結\n",
        "#建了一個基於 ResNet-34 的圖像分類模型，準備用 dls 中的數據進行訓練，並且希望看到準確率和錯誤率作為評估指標。模型從預訓練權重開始，而不是從隨機初始化的權重開始\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXZjQxp8OUpT"
      },
      "source": [
        "## 3.2儲存第一次訓練好的權重"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7F5wNLBYObEV"
      },
      "outputs": [],
      "source": [
        "myModel=myPath+'/resnet_stage-1.pkl'\n",
        "learn.export(myModel)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bAtMfpfykqp"
      },
      "source": [
        "## 3.3解凍權重再次訓練"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8f-6mphCyr4p"
      },
      "outputs": [],
      "source": [
        "# 調整學習率（learning rate）的過程\n",
        "learn.unfreeze()\n",
        "lr_min,lr_steep = learn.lr_find(suggest_funcs=(minimum, steep), end_lr=5, num_it=200) #這行程式碼的作用是尋找一個最佳的學習率範圍，幫助你選擇一個能夠加快訓練並且穩定收斂的學習率\n",
        "\n",
        "print(f\"Minimum/10: {lr_min:.2e}, steepest point: {lr_steep:.2e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ziUV_DKIzCSK"
      },
      "outputs": [],
      "source": [
        "learn.fit_one_cycle(6, lr_max=2.75e-04)\n",
        "#用 One Cycle Learning Rate 策略進行 6 次訓練，並在訓練過程中將學習率最大值設置為 2.75e-04"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RgixTMEOzOca"
      },
      "source": [
        "## 3.4儲存新的權重"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pTEHU0aNzRZK"
      },
      "outputs": [],
      "source": [
        "myModel=myPath+'/resnet_stage-2.pkl'\n",
        "learn.export(myModel)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sT7TAIvoQFG2"
      },
      "source": [
        "## 4.1結果檢核(Confusion Matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c0V-U0HxQMh9"
      },
      "outputs": [],
      "source": [
        "#contains interpretation methods for classification models\n",
        "interp = ClassificationInterpretation.from_learner(learn)\n",
        "#Plot the confusion matrix\n",
        "interp.plot_confusion_matrix()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4RLqdwj8Tlj"
      },
      "source": [
        "### 解釋一下confusion matrix\n",
        "*   elephant (大象)：20/20，完全正確\n",
        "*   giraffe (長頸鹿)：18/18，完全正確\n",
        "*   hippo (河馬)：20/21，幾乎完全正確\n",
        "*   zebra (斑馬)：19/19，完全正確\n",
        "*   猴子 (monkey) 類別有誤分類\n",
        "    *   14 張猴子圖片中，有 13 張正確分類，但 1 張被錯誤分類為河馬 (hippo)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7s01mQGIQ7hH"
      },
      "outputs": [],
      "source": [
        "interp.plot_top_losses(5, nrows=5) #顯示前 5 個錯誤最嚴重的分類結果"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fh0keQweRRop"
      },
      "source": [
        "## 預測"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YbQxw54XRaSl"
      },
      "outputs": [],
      "source": [
        "## 模型位置\n",
        "from fastbook import *\n",
        "from fastai.vision.widgets import *\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-eOi-vOZRyzz"
      },
      "source": [
        "## 5.1讀取先前訓練好的權重"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WMXRargZR20W"
      },
      "outputs": [],
      "source": [
        "myPath='/content/drive/MyDrive/DeepLearning/0225/models'\n",
        "myModel=myPath+'/resnet_stage-2.pkl'\n",
        "learn = load_learner(myModel)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFUOLq8S8Kvv"
      },
      "source": [
        "## 5.2讀取檔案並送入模型預測"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dNu3JVWU8O3p"
      },
      "outputs": [],
      "source": [
        "##執行預測 -method I\n",
        "# get_image_files is now available\n",
        "fnames_fire = get_image_files('/content/drive/MyDrive/DeepLearning/0225/dataset/demo/Satellite photos of the fire')\n",
        "fnames_Drought = get_image_files('/content/drive/MyDrive/DeepLearning/0225/dataset/demo/Drought satellite photos')\n",
        "fnames_floods = get_image_files('/content/drive/MyDrive/DeepLearning/0225/dataset/demo/Satellite photos of floods')\n",
        "fnames_volcanic = get_image_files('/content/drive/MyDrive/DeepLearning/0225/dataset/demo/Satellite photos of volcanic eruptions')\n",
        "fnames_heavy_rain = get_image_files('/content/drive/MyDrive/DeepLearning/0225/dataset/demo/Satellite photos of heavy rain')\n",
        "fnames_Typhoon = get_image_files('/content/drive/MyDrive/DeepLearning/0225/dataset/demo/Typhoon satellite photos')\n",
        "\n",
        "\n",
        "print(f\"Number of elephant images: {len(fnames_fire)}\")\n",
        "print(f\"Number of elephant images: {len(fnames_Drought)}\")\n",
        "print(f\"Number of elephant images: {len(fnames_floods)}\")\n",
        "print(f\"Number of elephant images: {len(fnames_volcanic)}\")\n",
        "print(f\"Number of elephant images: {len(fnames_heavy_rain)}\")\n",
        "print(f\"Number of elephant images: {len(fnames_Typhoon)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JBLED1Xl9QeE"
      },
      "outputs": [],
      "source": [
        "# Check if the list has enough elements before accessing them\n",
        "if len(fnames_fire) > 3:\n",
        "    pred_class,pred_idx,outputs = learn.predict(fnames_fire[3])\n",
        "    print(\"Actual: fire, Predicted = {}\".format(pred_class))\n",
        "else:\n",
        "    print(\"fnames_fire does not have enough elements to access index 3\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5zfYPrdNWkJ"
      },
      "source": [
        "## ROC curve"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIJ4lTbuIm9N"
      },
      "source": [
        "\n",
        "\n",
        "*   橫軸是假陽性率（FPR），縱軸是真陽性率（TPR）\n",
        "*   ROC 曲線（Receiver Operating Characteristic Curve，接收者操作特徵曲線）是一種用於評估分類模型性能的圖形工具，特別是在二元分類問題中（例如判斷「是/否」、「正/負」）\n",
        "*   AUC（Area Under the Curve） 是 ROC 曲線下的面積，範圍從 0 到 1\n",
        "*   AUC 的解釋\n",
        "  *   AUC=1：完美模型，100%正確分類。\n",
        "  *   AUC=0.5：隨機猜測，模型毫無區分能力（ROC 曲線是一條對角線）。\n",
        "  *   AUC<0.5：模型比隨機猜測還差（可能是標籤錯誤或模型反向預測）。\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WVNAyjR9NWNf"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "preds, y, loss = learn.get_preds(with_loss=True)\n",
        "preds, y = learn.get_preds(dl=dls.valid)\n",
        "# get accuracy\n",
        "acc = accuracy(preds, y)\n",
        "print('The accuracy is {0} %.'.format( 100* round( float(acc), 4)))\n",
        "\n",
        "class_num = dls.c\n",
        "class_name = dls.vocab\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "for i in range(class_num) :\n",
        "  probs = np.array(preds[:, i])\n",
        "  #compute ROC curve\n",
        "  fpr, tpr, thresholds = roc_curve(y, probs, pos_label=i)\n",
        "  #compute area under the curve\n",
        "  roc_auc = auc(fpr, tpr)\n",
        "  plt.plot(fpr, tpr, label='{0} (AUC={1})'.format( class_name[i], round(roc_auc, 3)))\n",
        "\n",
        "plt.plot([0,1], [0,1], color='navy', linestyle='--')\n",
        "plt.xlim([-0.01, 1.01])\n",
        "plt.ylim([-0.01, 1.01])\n",
        "plt.axis('square')\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"ROC curve\")\n",
        "plt.legend(loc=\"lower right\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O95WpTbq9AGQ"
      },
      "source": [
        "##6.V###tsisualization with Frad-CAM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhOjvyL3CgEH"
      },
      "source": [
        "Class Activation Mapping（類激活映射，簡稱CAM）是一種用於解釋卷積神經網路（CNN）預測的可視化技術。它可以幫助我們理解CNN在圖像分類任務中，哪些區域對最終預測貢獻最大。簡單來說，CAM生成一個熱圖（heatmap），顯示圖像中哪些部分對某個特定類別的預測最重要。\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OeFn3pmE9Fp3"
      },
      "outputs": [],
      "source": [
        "class Hook():\n",
        "  def __init__(self,m):\n",
        "    self.hook = m.register_forward_hook(self.hook_fn)\n",
        "  def hook_fn(self,m,i,o):self.stored = o.detach().clone()\n",
        "  def __enter__(self, *args):return self\n",
        "  def __exit__(self, *args):self.hook.remove()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "neBdCuMx-AtV"
      },
      "outputs": [],
      "source": [
        "class HookBwd():\n",
        "  def __init__(self,m):\n",
        "    self.hook = m.register_backward_hook(self.hook_fn)\n",
        "  def hook_fn(self,m,gi,go):self.stored = go[0].detach().clone()\n",
        "  def __enter__(self, *args):return self\n",
        "  def __exit__(self, *args):self.hook.remove()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RO8biGTb-NFa"
      },
      "source": [
        "##讀取要繪製的影像"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cbddjJ_1-P0j"
      },
      "outputs": [],
      "source": [
        "fnames_fire = get_image_files('/content/drive/MyDrive/DeepLearning/0225/dataset/demo/Satellite photos of the fire')\n",
        "test_dl = learn.dls.test_dl(fnames_fire, with_labels=True)\n",
        "\n",
        "fnames_Drought = get_image_files('/content/drive/MyDrive/DeepLearning/0225/dataset/demo/Drought satellite photos')\n",
        "test_dl = learn.dls.test_dl(fnames_Drought, with_labels=True)\n",
        "\n",
        "fnames_floods = get_image_files('/content/drive/MyDrive/DeepLearning/0225/dataset/demo/Satellite photos of floods')\n",
        "test_dl = learn.dls.test_dl(fnames_floods, with_labels=True)\n",
        "\n",
        "fnames_volcanic = get_image_files('/content/drive/MyDrive/DeepLearning/0225/dataset/demo/Satellite photos of volcanic eruptions')\n",
        "test_dl = learn.dls.test_dl(fnames_volcanic, with_labels=True)\n",
        "\n",
        "fnames_heavy_rain = get_image_files('/content/drive/MyDrive/DeepLearning/0225/dataset/demo/Satellite photos of heavy rain')\n",
        "test_dl = learn.dls.test_dl(fnames_heavy_rain, with_labels=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "agLrxO3D-7PT"
      },
      "outputs": [],
      "source": [
        "from torchvision.transforms.functional import to_tensor\n",
        "from fastai.vision.all import PILImage, Resize, ResizeMethod, PadMode  # 導入 fastai 模組\n",
        "fn = test_dl.items[1] #第2張影像\n",
        "x_dec = PILImage.create(fn);\n",
        "\n",
        "#Resize : 224填充黑邊\n",
        "rsz = Resize(224, method=ResizeMethod.Pad, pad_mode=PadMode.Zeros)\n",
        "x_dec = rsz(x_dec)\n",
        "x = to_tensor(x_dec)\n",
        "x.unsqueeze_(0)\n",
        "x.shape,type(x)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2KrlXraASLv"
      },
      "source": [
        "##繪製最後一層的feature map 的Grad-CAM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M_DKTCDCAX3R"
      },
      "outputs": [],
      "source": [
        "cls = 1\n",
        "with HookBwd(learn.model[0]) as hookg:\n",
        "  with Hook(learn.model[0]) as hook:\n",
        "    #output = learn.model.eval()(x,cuda())\n",
        "    output = learn.model.eval()(x.cpu())\n",
        "    act = hook.stored\n",
        "  output[0,cls].backward()\n",
        "  grad = hookg.stored\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y6BpwnK0A-Ge"
      },
      "outputs": [],
      "source": [
        "w = grad[0].mean(dim=[1,2], keepdim=True)\n",
        "cam_map = (w * act[0]).sum(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-i7aQdhWBlzo"
      },
      "source": [
        "##Demo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y3zqMIWKBpgf"
      },
      "outputs": [],
      "source": [
        "_,ax = plt.subplots()\n",
        "x_dec.show(ctx=ax)\n",
        "ax.imshow(cam_map.detach().cpu(), alpha=0.6, extent=(0,224,224,0),\n",
        "           interpolation='bilinear', cmap='magma')\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "IYE1-bfzA1tg"
      ],
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}